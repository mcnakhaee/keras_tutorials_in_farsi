{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\\n\\ndataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\\n                                    untar=True, cache_dir=\\'.\\',\\n                                    cache_subdir=\\'\\')\\n\\ndataset_dir = os.path.join(os.path.dirname(dataset), \\'aclImdb\\')'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>claim_summary</th>\n",
       "      <th>tags</th>\n",
       "      <th>org</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_role</th>\n",
       "      <th>date</th>\n",
       "      <th>body_text</th>\n",
       "      <th>conclusion_sum</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>links</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>واکسیناسیون و پایان کرونا در چین؟</td>\n",
       "      <td>کرونا به دلیل واکسیناسیون در چین پایان یافته است.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>social-media</td>\n",
       "      <td>شبکه‌های اجتماعی</td>\n",
       "      <td>\\n                            تلگرام، توییتر، ...</td>\n",
       "      <td>۱۳۹۹/۷/۷</td>\n",
       "      <td>سوالات درباره وضعیت کرونا در چین، یکی از سوژه‌...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...</td>\n",
       "      <td>https://www.instagram.com/p/CE_QEq-H6y3/;;http...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-09-28-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>آیا ۷۰ درصد تورم به دلیل ناتوانی دولت است و رب...</td>\n",
       "      <td>۷۰درصد تورم و گرانی ریشه در ناتوانی دولت دارد،...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ali-nazari</td>\n",
       "      <td>علی نظری</td>\n",
       "      <td>\\n                            روزنامه‌نگار و ن...</td>\n",
       "      <td>۱۳۹۹/۷/۵</td>\n",
       "      <td>یکی از مخاطبان فکت‌نامه در توییتر از ما خواسته...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...</td>\n",
       "      <td>https://twitter.com/nazary43/status/1308482215...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-09-26-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بیل گیتس و کاهش جمعیت جهان با واکسن؟</td>\n",
       "      <td>بیل گیتس می‌خواهد از واکسن‌ها برای کاهش جمعیت ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>press</td>\n",
       "      <td>مطبوعات و رسانه‌ها</td>\n",
       "      <td>\\n                            نشریات چاپی و آن...</td>\n",
       "      <td>۱۳۹۹/۷/۳</td>\n",
       "      <td>ادعاهای مربوط به خطرناک بودن واکسیناسیون، نه ت...</td>\n",
       "      <td>outrageous</td>\n",
       "      <td>\\n    متاسفانه مرورگر شما قابلیت پخش تصویر ندا...</td>\n",
       "      <td>https://www.tasnimnews.com/fa/news/1399/06/31/...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-09-24-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جوشانده سعال و درمان کرونا</td>\n",
       "      <td>جوشانده سعال داروی درمان کرونا است.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>press</td>\n",
       "      <td>مطبوعات و رسانه‌ها</td>\n",
       "      <td>\\n                            نشریات چاپی و آن...</td>\n",
       "      <td>۱۳۹۹/۷/۱</td>\n",
       "      <td>تلاش‌های متخصصان از چین و روسیه تا بریتانیا و ...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-08-05-b...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-09-22-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>آیا خسارت لغو سهمیه‌بندی بنزین در سال ۹۴، بیش ...</td>\n",
       "      <td>خسارت لغو سهمیه‌بندی بنزین در سال ۹۴ بیش از ۱۵...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alireza-zakani</td>\n",
       "      <td>علیرضا زاکانی</td>\n",
       "      <td>\\n                            رئیس مرکز پژوهش‌...</td>\n",
       "      <td>۱۳۹۹/۶/۲۹</td>\n",
       "      <td>علیرضا زاکانی، نماینده قم و رئیس مرکز پژوهش ها...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>\\n    گفته یا آمار را نمی‌توان با فکت‌های قابل...</td>\n",
       "      <td>https://rc.majlis.ir/fa/news/show/1607846;;htt...</td>\n",
       "      <td>https://factnameh.com/fact-checks/2020-09-19-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                  واکسیناسیون و پایان کرونا در چین؟   \n",
       "1  آیا ۷۰ درصد تورم به دلیل ناتوانی دولت است و رب...   \n",
       "2               بیل گیتس و کاهش جمعیت جهان با واکسن؟   \n",
       "3                         جوشانده سعال و درمان کرونا   \n",
       "4  آیا خسارت لغو سهمیه‌بندی بنزین در سال ۹۴، بیش ...   \n",
       "\n",
       "                                       claim_summary tags             org  \\\n",
       "0  کرونا به دلیل واکسیناسیون در چین پایان یافته است.  NaN    social-media   \n",
       "1  ۷۰درصد تورم و گرانی ریشه در ناتوانی دولت دارد،...  NaN      ali-nazari   \n",
       "2  بیل گیتس می‌خواهد از واکسن‌ها برای کاهش جمعیت ...  NaN           press   \n",
       "3               جوشانده سعال داروی درمان کرونا است.   NaN           press   \n",
       "4  خسارت لغو سهمیه‌بندی بنزین در سال ۹۴ بیش از ۱۵...  NaN  alireza-zakani   \n",
       "\n",
       "               entity                                        entity_role  \\\n",
       "0    شبکه‌های اجتماعی  \\n                            تلگرام، توییتر، ...   \n",
       "1            علی نظری  \\n                            روزنامه‌نگار و ن...   \n",
       "2  مطبوعات و رسانه‌ها  \\n                            نشریات چاپی و آن...   \n",
       "3  مطبوعات و رسانه‌ها  \\n                            نشریات چاپی و آن...   \n",
       "4       علیرضا زاکانی  \\n                            رئیس مرکز پژوهش‌...   \n",
       "\n",
       "        date                                          body_text  \\\n",
       "0   ۱۳۹۹/۷/۷  سوالات درباره وضعیت کرونا در چین، یکی از سوژه‌...   \n",
       "1   ۱۳۹۹/۷/۵  یکی از مخاطبان فکت‌نامه در توییتر از ما خواسته...   \n",
       "2   ۱۳۹۹/۷/۳  ادعاهای مربوط به خطرناک بودن واکسیناسیون، نه ت...   \n",
       "3   ۱۳۹۹/۷/۱  تلاش‌های متخصصان از چین و روسیه تا بریتانیا و ...   \n",
       "4  ۱۳۹۹/۶/۲۹  علیرضا زاکانی، نماینده قم و رئیس مرکز پژوهش ها...   \n",
       "\n",
       "  conclusion_sum                                         conclusion  \\\n",
       "0          false  \\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...   \n",
       "1          false  \\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...   \n",
       "2     outrageous  \\n    متاسفانه مرورگر شما قابلیت پخش تصویر ندا...   \n",
       "3          false  \\n    گفته یا آمار، نادرست است  یا دست‌کم سندی...   \n",
       "4        no_data  \\n    گفته یا آمار را نمی‌توان با فکت‌های قابل...   \n",
       "\n",
       "                                               links  \\\n",
       "0  https://www.instagram.com/p/CE_QEq-H6y3/;;http...   \n",
       "1  https://twitter.com/nazary43/status/1308482215...   \n",
       "2  https://www.tasnimnews.com/fa/news/1399/06/31/...   \n",
       "3  https://factnameh.com/fact-checks/2020-08-05-b...   \n",
       "4  https://rc.majlis.ir/fa/news/show/1607846;;htt...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://factnameh.com/fact-checks/2020-09-28-c...  \n",
       "1  https://factnameh.com/fact-checks/2020-09-26-i...  \n",
       "2  https://factnameh.com/fact-checks/2020-09-24-b...  \n",
       "3  https://factnameh.com/fact-checks/2020-09-22-c...  \n",
       "4  https://factnameh.com/fact-checks/2020-09-19-i...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/factnameh_2010_10_01.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poet</th>\n",
       "      <th>century</th>\n",
       "      <th>poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>رودکی</td>\n",
       "      <td>3</td>\n",
       "      <td>گر من این دوستی تو ببرم تا لب گور    بزنم نعره...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>رودکی</td>\n",
       "      <td>3</td>\n",
       "      <td>به حق نالم ز هجر دوست زارا    سحرگاهان چو بر گ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رودکی</td>\n",
       "      <td>3</td>\n",
       "      <td>به نام نیک تو، خواجه، فریفته نشوم    که نام نی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>رودکی</td>\n",
       "      <td>3</td>\n",
       "      <td>دلا، تا کی همی جویی منی را؟    چه داری دوست هر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>رودکی</td>\n",
       "      <td>3</td>\n",
       "      <td>گرفت خواهم زلفین عنبرین ترا    به بوسه نقش‌کنم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54519</th>\n",
       "      <td>اِ لیـــار    (جبار محمدی )</td>\n",
       "      <td>15</td>\n",
       "      <td>وطن خورشید آمال است.    مرا مامی کهن سال است. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54520</th>\n",
       "      <td>اِ لیـــار    (جبار محمدی )</td>\n",
       "      <td>15</td>\n",
       "      <td>در آسمان این خطّه    همیشه خورشید است    فرازِ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54521</th>\n",
       "      <td>اِ لیـــار    (جبار محمدی )</td>\n",
       "      <td>15</td>\n",
       "      <td>عمر است چون خزانه    هر لحظه اش چو دُرّی است  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54522</th>\n",
       "      <td>اِ لیـــار    (جبار محمدی )</td>\n",
       "      <td>15</td>\n",
       "      <td>بهار عمر ما دور جوانی است    پر از باران عشق و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54523</th>\n",
       "      <td>اِ لیـــار    (جبار محمدی )</td>\n",
       "      <td>15</td>\n",
       "      <td>حیات آوردگاه مرگ و امّید است.    کمال آرزو در ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54524 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              poet  century  \\\n",
       "0                            رودکی        3   \n",
       "1                            رودکی        3   \n",
       "2                            رودکی        3   \n",
       "3                            رودکی        3   \n",
       "4                            رودکی        3   \n",
       "...                            ...      ...   \n",
       "54519  اِ لیـــار    (جبار محمدی )       15   \n",
       "54520  اِ لیـــار    (جبار محمدی )       15   \n",
       "54521  اِ لیـــار    (جبار محمدی )       15   \n",
       "54522  اِ لیـــار    (جبار محمدی )       15   \n",
       "54523  اِ لیـــار    (جبار محمدی )       15   \n",
       "\n",
       "                                                    poem  \n",
       "0      گر من این دوستی تو ببرم تا لب گور    بزنم نعره...  \n",
       "1      به حق نالم ز هجر دوست زارا    سحرگاهان چو بر گ...  \n",
       "2      به نام نیک تو، خواجه، فریفته نشوم    که نام نی...  \n",
       "3      دلا، تا کی همی جویی منی را؟    چه داری دوست هر...  \n",
       "4      گرفت خواهم زلفین عنبرین ترا    به بوسه نقش‌کنم...  \n",
       "...                                                  ...  \n",
       "54519  وطن خورشید آمال است.    مرا مامی کهن سال است. ...  \n",
       "54520  در آسمان این خطّه    همیشه خورشید است    فرازِ...  \n",
       "54521  عمر است چون خزانه    هر لحظه اش چو دُرّی است  ...  \n",
       "54522  بهار عمر ما دور جوانی است    پر از باران عشق و...  \n",
       "54523  حیات آوردگاه مرگ و امّید است.    کمال آرزو در ...  \n",
       "\n",
       "[54524 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems = pd.read_csv('../data/poems/poems.tsv',sep = '\\t')\n",
    "poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 32\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok  = \"<OOV>\"\n",
    "training_size = 40000\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "سطرهای دیتاست را به صورت تصادفی بر می زنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = poems.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poet</th>\n",
       "      <th>century</th>\n",
       "      <th>poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27828</th>\n",
       "      <td>سلمان ساوجی</td>\n",
       "      <td>8</td>\n",
       "      <td>شنودم که می‌گفت بشوده به شیخ     که احوال حاجی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44146</th>\n",
       "      <td>صائب تبریزی</td>\n",
       "      <td>11</td>\n",
       "      <td>هر کس که در نماز به روی و ریا رود    بر پشت با...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10639</th>\n",
       "      <td>عطار</td>\n",
       "      <td>6</td>\n",
       "      <td>ای خلق چرا در تب و تفتید آخر    نابوده و ناآمد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29281</th>\n",
       "      <td>شاه نعمت‌الله ولی</td>\n",
       "      <td>8</td>\n",
       "      <td>رنج غربت تو از غریبان پرس    دردمندی ز دردمندا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>عطار</td>\n",
       "      <td>6</td>\n",
       "      <td>آن مجرد باطن و ظاهر، آن مسافر غایب و حاضر، آن ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poet  century  \\\n",
       "27828        سلمان ساوجی        8   \n",
       "44146        صائب تبریزی       11   \n",
       "10639               عطار        6   \n",
       "29281  شاه نعمت‌الله ولی        8   \n",
       "14235               عطار        6   \n",
       "\n",
       "                                                    poem  \n",
       "27828  شنودم که می‌گفت بشوده به شیخ     که احوال حاجی...  \n",
       "44146  هر کس که در نماز به روی و ریا رود    بر پشت با...  \n",
       "10639  ای خلق چرا در تب و تفتید آخر    نابوده و ناآمد...  \n",
       "29281  رنج غربت تو از غریبان پرس    دردمندی ز دردمندا...  \n",
       "14235  آن مجرد باطن و ظاهر، آن مسافر غایب و حاضر، آن ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems['poet_cat'] = poems['poet'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'هر کس که در نماز به روی و ریا رود    بر پشت بام کعبه به کسب هوا رود    بر عشق رهروی که کند عقل اختیار    از خضر بگسلد ز پی نقش پا رود    تا باز می کنند نظر بسته می شود    از هر دری که اهل طلب بینوا رود    این قفل وا شود به کلید شکستگی    هردانه ای که نرم شد از آسیا رود    بینا کسی بود که نهد پا به احتیاط    در وادیی که کوردر او بی عصا رود    خواب غرور لازم ارباب دولت است    کی تیرگی ز سایه بال هما رود    بیرون نرفت سرمه به شستن ز چشم یار    دود از سیاه خانه لیلی کجا رود    نادان شود ز اهل بصیرت به خاکمال    کوتاه دیدگی اگر از توتیا رود    بی مغز را ز جای برد گفتگوی پوچ    کاه سبک عنان ز پی کهربا رود    هر کس هرآنچه یافته زین خاک یافته است    از آستان میکده صائب کجارود'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_text = poems.poem.values.tolist()\n",
    "poems_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = poems.poet_cat.values.tolist()\n",
    "labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا بیایید ببینم که چه تعداد شاعر در دیتاست ما حضور دارند یا به عبارتی دیگر مساله دستی بندی ما چند کلاس دارد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_poems = poems_text[:training_size]\n",
    "training_labels = labels[:training_size]\n",
    "test_poems = poems_text[training_size:]\n",
    "test_labels = labels[training_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size,\n",
    "                     oov_token = oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(training_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "#word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(training_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 70,\n",
       " 4,\n",
       " 6,\n",
       " 822,\n",
       " 5,\n",
       " 49,\n",
       " 2,\n",
       " 1,\n",
       " 299,\n",
       " 10,\n",
       " 311,\n",
       " 702,\n",
       " 630,\n",
       " 5,\n",
       " 1,\n",
       " 362,\n",
       " 299,\n",
       " 10,\n",
       " 42]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sequences[1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'هر کس که در نماز به '"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_poems[1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = pad_sequences(training_sequences,\n",
    "                                maxlen=max_length,\n",
    "                                padding=padding_type,\n",
    "                               truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ای خلق چرا در تب و تفتید آخر    نابوده و ناآمده رفتید آخر    ای بیخبران این در و درگاه عظیم    خالی مگذارید و مخفتید آخر'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_poems[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26, 147, 167,   6,   1,   2,   1, 137,   1,   2,   1,   1, 137,\n",
       "        26,   1,  14,   6,   2,   1,   1, 688,   1,   2,   1, 137,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_padded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_poems)\n",
    "test_padded = pad_sequences(test_sequences,\n",
    "                             maxlen=max_length,\n",
    "                                padding=padding_type,\n",
    "                               truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = np.array(training_labels).reshape(-1,1) \n",
    "test_labels = np.array(test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33],\n",
       "       [39],\n",
       "       [28],\n",
       "       [39],\n",
       "       [33],\n",
       "       [ 6],\n",
       "       [ 9],\n",
       "       [58],\n",
       "       [39]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size,\n",
    "                                  embedding_dim,\n",
    "                                 input_length = max_length),\n",
    "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "                             tf.keras.layers.Dense(32,activation = 'relu'),\n",
    "                             tf.keras.layers.Dense(67,activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 32)           32000     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 67)                2211      \n",
      "=================================================================\n",
      "Total params: 52,931\n",
      "Trainable params: 52,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 33s 29ms/step - loss: 2.9622 - accuracy: 0.2678 - val_loss: 2.5308 - val_accuracy: 0.3417\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 33s 30ms/step - loss: 2.4358 - accuracy: 0.3626 - val_loss: 2.3059 - val_accuracy: 0.3860\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 38s 34ms/step - loss: 2.1839 - accuracy: 0.4133 - val_loss: 2.1525 - val_accuracy: 0.4200\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 37s 33ms/step - loss: 2.0407 - accuracy: 0.4498 - val_loss: 2.0638 - val_accuracy: 0.4532\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 33s 30ms/step - loss: 1.9186 - accuracy: 0.4841 - val_loss: 1.9704 - val_accuracy: 0.4765\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_padded,training_labels,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=32,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "حالا بیاید معماری مدل شبکه عصبی را تغییر دهیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### پیش پردازش بیشتر داده ها\n",
    "یک کار دیگری که می توانیم انجام بدهیم این است که کلمات توقف را حذف کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/poems/stop_words.txt','r',encoding='utf8') as f:\n",
    "    stop_words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ولیکن'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### تمرین\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
