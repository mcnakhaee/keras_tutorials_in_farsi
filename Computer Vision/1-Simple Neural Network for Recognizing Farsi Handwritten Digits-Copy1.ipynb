{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoda = scipy.io.loadmat('data\\\\Data_hoda_full.mat')\n",
    "type(hoda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'Data', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(hoda.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(hoda['Data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(hoda['Data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(hoda['labels']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(hoda['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "data= hoda['Data'].reshape(-1)\n",
    "print(data.shape)\n",
    "\n",
    "labels = hoda['labels'].reshape(-1)\n",
    "print(labels .shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic1_data = data[1]\n",
    "pic1_label = labels[1]\n",
    "pic1_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEsCAYAAABQenHyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABPVJREFUeJzt3FFu1DAARdEazf63HD5QBS0XaerSxHHP2QAmk175J28cx/ECwFs/rj4AwIrEESCII0AQR4AgjgBBHAGCOAIEcQQI4ggQHlcf4B98tsMbY4xT/h1fjG3v6RfJzREgiCNAEEeAII4AQRwBgjgCBHEECOIIEMQRIIgjQBBHgCCOAGHV4Qk2dtaIxIzZsxms2I+bI0AQR4AgjgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBgjgCBKs8TFt5XedsM8/Cks/a3BwBgjgCBHEECOIIEMQRIIgjQBBHgCCOAEEcAYI4AgRxBAjiCBAMT8BFjFWszc0RIIgjQBBHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgDB8MSGZgYNgLfcHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBgjgCBHEECOIIEAxPLMyABO/NvhPHcfznk+zPzREgiCNAEEeAII4AQRwBgjgCBHEECOIIEMQRIIgjQBBHgCCOAEEcAYJVnpNY2Pltx4WY1X/fmfPt+Dt9hJsjQBBHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGC4Qmmffdhgj/NPIvVxyq+OzdHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGCOAKEseh4wJKHerXjYMCi7wHvrP7u3eA9evoBujkCBHEECOIIEMQRIIgjQBBHgCCOAEEcAYI4AgRxBAjiCBDEESCII0B4XH2Aq62+cjLjBssobGrm72nV99XNESCII0AQR4AgjgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AYZvhiR0HJOA7mP3b/erBCjdHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGCOAKEbYYndvTVH9ZzP7PvhGGWj3NzBAjiCBDEESCII0AQR4AgjgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAMFZcfhljrHeoT1rxOe/uzCWaHX/fHZd8juN4+j/l5ggQxBEgiCNAEEeAII4AQRwBgjgCBHEECOIIEMQRIIgjQBBHgPC4+gDwjNVHEGbOt+NYxU7cHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBgjgCBHEECOIIEAxPTDAY8Dmrj0jAy4ubI0ASR4AgjgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBgjgCBHEECOIIEMQRIIgjQBBHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4DwuPoA3NcY4+oj3NrM8zuO47R/a3Wzz+JZbo4AQRwBgjgCBHEECOIIEMQRIIgjQBBHgCCOAEEcAYI4AgRxBAhLDk/MfFA++2H9V3+8foUdRwb4xW97HjdHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGCOAKEJYcnZhiQ4G7OHFhZ2ap/u26OAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGCOAIEcQQI4ggQtlnlWd2OayqzVl1huQPP7jxujgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBgjgCBHEECMOH7AB/c3MECOIIEMQRIIgjQBBHgCCOAEEcAYI4AgRxBAjiCBDEESCII0AQR4AgjgBBHAGCOAIEcQQI4ggQxBEgiCNAEEeAII4AQRwBwk81KGt6nLkh5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f45e49e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (5,5) )\n",
    "plt.axis('off')\n",
    "plt.imshow(pic1_data,cmap= matplotlib.cm.Greys)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(pic1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 21)\n",
      "(10, 15)\n",
      "(36, 17)\n",
      "(36, 28)\n",
      "(12, 14)\n",
      "(26, 27)\n",
      "(27, 28)\n",
      "(13, 19)\n",
      "(27, 20)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resized = np.array([cv2.resize(img, dsize=(5, 5)) for img in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(data_resized[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 255,   0,   0],\n",
       "       [  0, 255, 128, 255,   0],\n",
       "       [204,  51,   0,  51, 204],\n",
       "       [255,   0, 255,   0, 255],\n",
       "       [ 51, 229, 255, 153, 204]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_resized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAACPCAYAAADKiCjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAflJREFUeJzt3MGJAkEQQNGeZdMQU9EAjMg4jMdcTGQ2BP/BQmZ57yxFM3z6MIy17fu+oPj59gE4DrGQiYVMLGRiIRMLmVjIxEImFrLfobmHei28bdvHZx7wzfjbh+BmIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWsqmv+0dMfIW/1lqPx+PjM6fO+s1/DbhZyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFbOTr/uv1OjF2vV6vkbmn0+njM2+328dnrjX3bJ/P59vfuFnIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQbRPrvbdtG9kZPrWKfGJ1+pHOutZa+76/HexmIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWspF17FNr08/n88jcCff7fWTu5XIZmVu4WcjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhWxkdz//k5uFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFrI/StUpuBwp8R4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f45f4b2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (2,2) )\n",
    "plt.axis('off')\n",
    "plt.imshow(data_resized[1],cmap= matplotlib.cm.Greys)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.50196078, 1.        , 0.        ],\n",
       "       [0.8       , 0.2       , 0.        , 0.2       , 0.8       ],\n",
       "       [1.        , 0.        , 1.        , 0.        , 1.        ],\n",
       "       [0.2       , 0.89803922, 1.        , 0.6       , 0.8       ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = data_resized/255\n",
    "data_norm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2,2) )\n",
    "plt.axis('off')\n",
    "plt.imshow(data_resized[1],cmap= matplotlib.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAACPCAYAAADKiCjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAflJREFUeJzt3MGJAkEQQNGeZdMQU9EAjMg4jMdcTGQ2BP/BQmZ57yxFM3z6MIy17fu+oPj59gE4DrGQiYVMLGRiIRMLmVjIxEImFrLfobmHei28bdvHZx7wzfjbh+BmIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWsqmv+0dMfIW/1lqPx+PjM6fO+s1/DbhZyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFbOTr/uv1OjF2vV6vkbmn0+njM2+328dnrjX3bJ/P59vfuFnIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQbRPrvbdtG9kZPrWKfGJ1+pHOutZa+76/HexmIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWspF17FNr08/n88jcCff7fWTu5XIZmVu4WcjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFjKxkImFTCxkYiETC5lYyMRCJhYysZCJhWxkdz//k5uFTCxkYiETC5lYyMRCJhYysZCJhUwsZGIhEwuZWMjEQiYWMrGQiYVMLGRiIRMLmVjIxEImFrI/StUpuBwp8R4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f45e4707b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (2,2) )\n",
    "plt.axis('off')\n",
    "plt.imshow(data_norm[1],cmap= matplotlib.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 5, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 25)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = data_norm.reshape(60000,25)\n",
    "data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(data_norm,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train_cat = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test_cat = keras.utils.to_categorical(y_test,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training dataset is: (45000, 25)\n",
      "size of test dataset is: (15000, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"size of training dataset is: \" +  str(X_train.shape))\n",
    "print(\"size of test dataset is: \" +  str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50,activation = 'sigmoid', input_shape = (25,)))\n",
    "model.add(Dense(50,activation = 'sigmoid'))\n",
    "model.add(Dense(50,activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 1s 18us/step - loss: 2.2838 - acc: 0.1876\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 1.9674 - acc: 0.5026\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 1.3649 - acc: 0.5992\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 1.1067 - acc: 0.6785\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.9156 - acc: 0.7428\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.7535 - acc: 0.7798\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.6319 - acc: 0.8132\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.5415 - acc: 0.8362\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.4767 - acc: 0.8538\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.4312 - acc: 0.8669\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.3984 - acc: 0.8755\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.3740 - acc: 0.8814\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.3548 - acc: 0.8866\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.3389 - acc: 0.8906\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.3246 - acc: 0.8950\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.3127 - acc: 0.8995\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.3024 - acc: 0.9030\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2931 - acc: 0.9063\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2851 - acc: 0.9086\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.2774 - acc: 0.9112\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2710 - acc: 0.9134\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2644 - acc: 0.9162\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2592 - acc: 0.9168\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2548 - acc: 0.9181\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2499 - acc: 0.9194\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2457 - acc: 0.9213\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2419 - acc: 0.9222\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2383 - acc: 0.9236\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2345 - acc: 0.9248\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2314 - acc: 0.9254\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.2282 - acc: 0.9267\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.2257 - acc: 0.9280\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2229 - acc: 0.9290\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2197 - acc: 0.9293\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2174 - acc: 0.9300\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2150 - acc: 0.9309\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2132 - acc: 0.9303\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2098 - acc: 0.9325\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2080 - acc: 0.9321\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2055 - acc: 0.9339\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.2029 - acc: 0.9342\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2013 - acc: 0.9346\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1994 - acc: 0.9350\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1965 - acc: 0.9358\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1949 - acc: 0.9363\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1931 - acc: 0.9366\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.1912 - acc: 0.9379\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1900 - acc: 0.9381\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1874 - acc: 0.9381\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1860 - acc: 0.9386\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1839 - acc: 0.9393\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1823 - acc: 0.9404\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1811 - acc: 0.9404\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1797 - acc: 0.9410\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.1776 - acc: 0.9418\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1764 - acc: 0.9417\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1747 - acc: 0.9426\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1740 - acc: 0.9428\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1729 - acc: 0.9431\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1710 - acc: 0.9429\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1696 - acc: 0.9436\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1680 - acc: 0.9450\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1671 - acc: 0.9445\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1657 - acc: 0.9452\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1649 - acc: 0.9452\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.1637 - acc: 0.9456\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1626 - acc: 0.9458\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1615 - acc: 0.9469\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1603 - acc: 0.9467\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1596 - acc: 0.9470\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1587 - acc: 0.9471\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1574 - acc: 0.9479\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1570 - acc: 0.9485\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1561 - acc: 0.9484\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1546 - acc: 0.9488\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1544 - acc: 0.9485\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1547 - acc: 0.9481\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1529 - acc: 0.9495\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1516 - acc: 0.9489\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1512 - acc: 0.9496\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1501 - acc: 0.9499\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1495 - acc: 0.9506\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1489 - acc: 0.9508\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1482 - acc: 0.9509\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1475 - acc: 0.9504\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1468 - acc: 0.9509\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1458 - acc: 0.9508\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1456 - acc: 0.9515\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1447 - acc: 0.9516\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1443 - acc: 0.9516\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1431 - acc: 0.9519\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1429 - acc: 0.9521\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1423 - acc: 0.9522\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1420 - acc: 0.9525\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1423 - acc: 0.9526\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1413 - acc: 0.9524\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1396 - acc: 0.9527\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1398 - acc: 0.9534\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1394 - acc: 0.9534\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1385 - acc: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f400a7e8d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train_cat, batch_size = 512, epochs=100,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14266455941200257, 0.9506000000317891]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 1, ..., 9, 1, 9], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 1, ..., 8, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50,activation = 'relu', input_shape = (25,)))\n",
    "model.add(Dense(50,activation = 'relu'))\n",
    "model.add(Dense(50,activation = 'relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 1s 22us/step - loss: 1.3357 - acc: 0.6196\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.3556 - acc: 0.8860\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.2684 - acc: 0.9137\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.2394 - acc: 0.9220\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2209 - acc: 0.9276\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.2071 - acc: 0.9322\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1959 - acc: 0.9356\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1875 - acc: 0.9386\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1794 - acc: 0.9407\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1766 - acc: 0.9412\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1692 - acc: 0.9444\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1659 - acc: 0.9444\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1607 - acc: 0.9462\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1576 - acc: 0.9470\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1540 - acc: 0.9483\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1507 - acc: 0.9494\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1481 - acc: 0.9507\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1472 - acc: 0.9505\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1441 - acc: 0.9515\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1421 - acc: 0.9522\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1413 - acc: 0.9530\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1391 - acc: 0.9538\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1377 - acc: 0.9534\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1354 - acc: 0.9541\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1359 - acc: 0.9534\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 0s 9us/step - loss: 0.1332 - acc: 0.9547\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1319 - acc: 0.9562\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1318 - acc: 0.9552\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1286 - acc: 0.9567\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1282 - acc: 0.9558\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1269 - acc: 0.9568\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1267 - acc: 0.9567\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1239 - acc: 0.9580\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 0s 10us/step - loss: 0.1237 - acc: 0.9588\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1243 - acc: 0.9573\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1216 - acc: 0.9589\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1207 - acc: 0.9590\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1198 - acc: 0.9591\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1192 - acc: 0.9593\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1176 - acc: 0.9602\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1185 - acc: 0.9589\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1168 - acc: 0.9604\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1166 - acc: 0.9602\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1158 - acc: 0.9605\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1156 - acc: 0.9605\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1152 - acc: 0.9605\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1136 - acc: 0.9616\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1130 - acc: 0.9614\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 1s 16us/step - loss: 0.1132 - acc: 0.9611\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1123 - acc: 0.9615\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1115 - acc: 0.9623\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1107 - acc: 0.9622\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1101 - acc: 0.9625\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1102 - acc: 0.9626\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1096 - acc: 0.9624\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1080 - acc: 0.9631\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1087 - acc: 0.9629\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1076 - acc: 0.9622\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1074 - acc: 0.9629\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 1s 16us/step - loss: 0.1056 - acc: 0.9635\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1078 - acc: 0.9634\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1047 - acc: 0.9639\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1069 - acc: 0.9626\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.1039 - acc: 0.9638\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1038 - acc: 0.9648\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.1038 - acc: 0.9642\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1032 - acc: 0.9646\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1023 - acc: 0.9647\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1027 - acc: 0.9646\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1031 - acc: 0.9634\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1023 - acc: 0.9643\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1034 - acc: 0.9638\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1009 - acc: 0.9648\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 1s 11us/step - loss: 0.1012 - acc: 0.9647: 0s - loss: 0.1009 - acc: 0\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.1002 - acc: 0.9648\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.0990 - acc: 0.9656\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.1004 - acc: 0.9649\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 0s 11us/step - loss: 0.0990 - acc: 0.9656\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 1s 12us/step - loss: 0.0989 - acc: 0.9657\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0986 - acc: 0.9654\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0980 - acc: 0.9658\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0966 - acc: 0.9662\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0976 - acc: 0.9661\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0982 - acc: 0.9654\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0978 - acc: 0.9661\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0967 - acc: 0.9662\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0948 - acc: 0.9668\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0954 - acc: 0.9667\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 1s 16us/step - loss: 0.0959 - acc: 0.9670\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 1s 18us/step - loss: 0.0947 - acc: 0.9668\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 1s 22us/step - loss: 0.0943 - acc: 0.9673\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.0943 - acc: 0.9670\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 1s 17us/step - loss: 0.0933 - acc: 0.9678\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0935 - acc: 0.9667\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0936 - acc: 0.9670\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0925 - acc: 0.9676\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 1s 13us/step - loss: 0.0943 - acc: 0.9666\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0933 - acc: 0.9673\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 1s 14us/step - loss: 0.0930 - acc: 0.9674\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 1s 15us/step - loss: 0.0915 - acc: 0.9678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f402f9cfd0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train_cat, batch_size = 512, epochs=100,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "توابع فعال سازی ReLu فاقد مشکل نیستند. \n",
    "\n",
    "مثلا یک مشکل رایج توابع فعال سازی ReLu نورون های در حال مرگ است. یعنی برخی از نورون ها در طول فرآیند آموزش تغییری پیدا نمی کنند و خروجی آن ها به صوت ثابت برابر با 0 خواهد بود و دیگر گرادیان نزولی وزن های آن ها را نمی تواند به روز رسانی کند. برای حل این مشکل می توانیم از سایر توابع فعال سازی variant ReLU مثل Leaky ReLU استفاده کنیم.\n",
    "\n",
    "در حقیقت طبق یافته بعضی از محققین یادگیری عمیق، این  توابع فعال سازی بهتر از ReLU عمل می کنند.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU,ELU,LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1250/1*4ZEDRpFuCIpUjNgjDdT2Lg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer re_lu is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26af6629308>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10,10,num =  100)\n",
    "layer = ReLU()\n",
    "plt.plot(x,layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer elu is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26af8ec6b08>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = ELU()\n",
    "plt.plot(x,layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer leaky_re_lu is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26aff91fc88>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = LeakyReLU()\n",
    "plt.plot(x,layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع فعال سازی ELU نرخ همگرایی سریع تری دارد ولی به صورت کلی کندتر از ReLU و بقیه varaint های آن است.\n",
    "\n",
    "به صورت کلی اگر بخواهیم بر اساس عملکرد مقایسه کنیم انتخاب توابع فعال سازی به صورت زیر خواهد بود:\n",
    "\n",
    "SELU > ELU > leaky\n",
    "ReLU (and its variants) > ReLU > tanh > logistic\n",
    "\n",
    "اگر شبکه ما فقط از لایه های Dense\n",
    "\n",
    "اگر عملکرد مدل برای ما مهم است از ELU استفاده می کنیم.\n",
    "\n",
    "اگر برای ما سرعت آموزش مدل مهم است از ReLU استفاده می کنیم.\n",
    "\n",
    "اگر با یک دیتاست خیلی بزر سر و کار داریم از PReLU استفاده می کنیم.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تنظیم سازی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight decay (l2 kernel regularisation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-27375924e36c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model.add(Dense(50,activation = 'relu', input_shape = (25,)),\n\u001b[0;32m      3\u001b[0m           \u001b[0mkernel_regularizer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m          bias_regularizer = tf.keras.regularizers.l2(0.01))\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50,activation = 'relu', input_shape = (25,)),\n",
    "          kernel_regularizer =tf.keras.regularizers.l2(0.01),\n",
    "         bias_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "model.add(Dense(50,activation = 'relu'))\n",
    "model.add(Dense(50,activation = 'relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " می توانیم از هر دو نوع تنظیم سازی استفاده کنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### استفاده از حذف تصادفی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "یک روش دیگر برای مواجه به محو گرادیان ها است.\n",
    "\n",
    "چون که باید یک مجموعه پارامتر در هر مینی بچ محاسبه کنیم فرآیند آموزش را کمی کندتر می کند ولی در نهایت چون که همگرایی را سریع تر می کند زمان نهایی کمتر خواهد شد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد از هر لایه دارای تابع فعال سازی batch norm را پیاده سازی می کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.BatchNormalization()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that there are some parameters and hyperparameters associated with batch normalisation.\n",
    "\n",
    "The hyperparameter momentum is the weighting given to the previous running mean when re-computing it with an extra minibatch. By default, it is set to 0.99.\n",
    "\n",
    "The hyperparameter  𝜖  is used for numeric stability when performing the normalisation over the minibatch. By default it is set to 0.001.\n",
    "\n",
    "The parameters  𝛽  and  𝛾  are used to implement an affine transformation after normalisation. By default,  𝛽  is an all-zeros vector, and  𝛾  is an all-ones vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7bfb8a6d650e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add a customised batch normalisation layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.add(tf.keras.layers.BatchNormalization(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Add a customised batch normalisation layer\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(\n",
    "    momentum=0.95, \n",
    "    epsilon=0.005,\n",
    "    axis = -1,\n",
    "    beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "    gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تعداد پارامترهایی که batch norm به شبکه اضافه می کند."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
