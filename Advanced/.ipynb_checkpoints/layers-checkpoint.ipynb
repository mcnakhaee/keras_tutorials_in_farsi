{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D,Dense,Flatten,Conv2D\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## نگاهی عمیق تر به لایه ها\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### دسترسی به وزن های لایه ها\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h5py' has no attribute 'File'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-254134de6fbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m base_model = tf.keras.applications.ResNet50V2(weights= 'imagenet',\n\u001b[0;32m      2\u001b[0m                                          \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                          include_top = False)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet_v2.py\u001b[0m in \u001b[0;36mResNet50V2\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[0mpooling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m       \u001b[0mclassifier_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier_activation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m   )\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         file_hash=file_hash)\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[0;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m   1257\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   1258\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'h5py' has no attribute 'File'"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(weights= 'imagenet',\n",
    "                                         input_shape = (150,150,3),\n",
    "                                         include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### لایه های lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ساخت لایه های اختصاصی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "برای ساخت یک لایه کراس سه تابع را باید در زمان ایجاد کلاس این لایه پیاده سازی کنیم:\n",
    "\n",
    "1. یک تابع که وزن های قابل آموزش مدل را تعریف می کند. (تابع build)\n",
    "\n",
    "2. یک تابع که منطق لایه را مشخص می کند (تابع call)\n",
    "\n",
    "3. و در نهایت یک تابع که ابعاد خروجی را محاسبه و تعیین می کند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "لایه های تعریف شده باید از کلاس tf.keras.layers.Layers به ارث برده شده باشند."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### پیاده سازی لایه  Noisy Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyRelu(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(NoisyRelu,self).__init__(**kwargs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگر به تعریف تابع فعال سازی noisy relu دقت کرده باشید می بینید که این لایه هیچ پارامتر آموزش پذیری ندارد. برای همین نیازی به تابع build نداریم.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self,x):\n",
    "    tf.maximum(0, x + tf.random.normal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output_shape(self,input_shape):\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.16257451]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape = (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا می توانیم همه این ها را کنار هم قرار دهیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyRelu(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(NoisyRelu,self).__init__(**kwargs)\n",
    "    def call(self,x):\n",
    "        return tf.maximum(0.0, x + tf.random.normal(shape = (1,1)))\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### آموزش و امتحان لایه جدید ساخته شده"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 15,kernel_size=3, input_shape = (28,28,1)))\n",
    "model.add(NoisyRelu())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 15)        150       \n",
      "_________________________________________________________________\n",
      "noisy_relu_6 (NoisyRelu)     (None, 26, 26, 15)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 15)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2535)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               253600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 254,760\n",
      "Trainable params: 254,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### پیاده سازی لایه Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا نوبت این است که تابع build را تعریف کنیم.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self,input_shape):\n",
    "    self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(Layer):\n",
    "    \"\"\"\n",
    "        Implementation according to:\n",
    "            \"Attention is all you need\" by A Vaswani, N Shazeer, N Parmar (2017)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):    \n",
    "        self._return_attention = return_attention\n",
    "        self.supports_masking = True\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        self._validate_input_shape(input_shape)\n",
    "\n",
    "        if not self._return_attention:\n",
    "            return input_shape[-1]\n",
    "        else:\n",
    "            return [input_shape[-1], [input_shape[0][0], input_shape[0][1], input_shape[1][2]]]\n",
    "    \n",
    "    def _validate_input_shape(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError(\"Layer received an input shape {0} but expected three inputs (Q, V, K).\".format(input_shape))\n",
    "        else:\n",
    "            if input_shape[0][0] != input_shape[1][0] or input_shape[1][0] != input_shape[2][0]:\n",
    "                raise ValueError(\"All three inputs (Q, V, K) have to have the same batch size; received batch sizes: {0}, {1}, {2}\".format(input_shape[0][0], input_shape[1][0], input_shape[2][0]))\n",
    "            if input_shape[0][1] != input_shape[1][1] or input_shape[1][1] != input_shape[2][1]:\n",
    "                raise ValueError(\"All three inputs (Q, V, K) have to have the same length; received lengths: {0}, {1}, {2}\".format(input_shape[0][0], input_shape[1][0], input_shape[2][0]))\n",
    "            if input_shape[0][2] != input_shape[1][2]:\n",
    "                raise ValueError(\"Input shapes of Q {0} and V {1} do not match.\".format(input_shape[0], input_shape[1]))\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self._validate_input_shape(input_shape)\n",
    "        \n",
    "        super(ScaledDotProductAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        q, k, v = x\n",
    "        d_k = q.shape.as_list()[2]\n",
    "\n",
    "        # in pure tensorflow:\n",
    "        # weights = tf.matmul(x_batch, tf.transpose(y_batch, perm=[0, 2, 1]))\n",
    "        # normalized_weights = tf.nn.softmax(weights/scaling)\n",
    "        # output = tf.matmul(normalized_weights, x_batch)\n",
    "        \n",
    "        weights = K.batch_dot(q,  k, axes=[2, 2])\n",
    "\n",
    "        if mask is not None:\n",
    "            # add mask weights\n",
    "            if isinstance(mask, (list, tuple)):\n",
    "                if len(mask) > 0:\n",
    "                    raise ValueError(\"mask can only be a Tensor or a list of length 1 containing a tensor.\")\n",
    "\n",
    "                mask = mask[0]\n",
    "\n",
    "            weights += -1e10*(1-mask)\n",
    "\n",
    "        normalized_weights = K.softmax(weights / np.sqrt(d_k))\n",
    "        output = K.batch_dot(normalized_weights, v)\n",
    "        \n",
    "        if self._return_attention:\n",
    "            return [output, normalized_weights]\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### منابع"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zimmerrol/keras-utility-layer-collection/blob/master/kulc/layer_normalization.py\n",
    "https://github.com/zimmerrol/keras-utility-layer-collection\n",
    "    https://github.com/Zelgunn/CustomKerasLayers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
